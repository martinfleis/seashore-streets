{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure contextual morphometric characters\n",
    "\n",
    "Computational notebook 03 for Climate adaptation plans in the context of coastal settlements: the case of Portugal.\n",
    "\n",
    "Date: 27/06/2020\n",
    "\n",
    "---\n",
    "\n",
    "This notebook measure contextual (code uses older term summative) characters. It requires data from `02_Measure_morphometric_characters.ipynb` and additional manually assigned attributes:\n",
    "\n",
    "- Attribute `part` in `name_blg` for cases which were divided into parts. Each part should be marked by unique `int`.\n",
    "- Attribute `case` in `name_str` capturing which LineStrings form the seashore street itself. (1 - True)\n",
    "\n",
    "Structure of GeoPackages:\n",
    "\n",
    "```\n",
    "./data/\n",
    "    atlantic.gpkg\n",
    "        name_blg    - Polygon layers\n",
    "        name_str    - LineString layers\n",
    "        name_case   - Polygon layers\n",
    "        name_tess   - Polygon layers\n",
    "        name_blocks - Polygon layers\n",
    "        ...\n",
    "     preatl.gpkg\n",
    "        name_blg\n",
    "        name_str\n",
    "        name_case\n",
    "        ...\n",
    "     premed.gpkg\n",
    "        name_blg\n",
    "        name_str\n",
    "        name_case\n",
    "        ...\n",
    "     med.gpkg\n",
    "        name_blg\n",
    "        name_str\n",
    "        name_case\n",
    "        ...\n",
    "```\n",
    "\n",
    "CRS of the original data is EPSG:3763.\n",
    "\n",
    "```\n",
    "<Projected CRS: EPSG:3763>\n",
    "Name: ETRS89 / Portugal TM06\n",
    "Axis Info [cartesian]:\n",
    "- X[east]: Easting (metre)\n",
    "- Y[north]: Northing (metre)\n",
    "Area of Use:\n",
    "- name: Portugal - mainland - onshore\n",
    "- bounds: (-9.56, 36.95, -6.19, 42.16)\n",
    "Coordinate Operation:\n",
    "- name: Portugual TM06\n",
    "- method: Transverse Mercator\n",
    "Datum: European Terrestrial Reference System 1989\n",
    "- Ellipsoid: GRS 1980\n",
    "- Prime Meridian: Greenwich\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import momepy as mm\n",
    "import pandas as pd\n",
    "import fiona\n",
    "import inequality\n",
    "from inequality.theil import Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.8.13', '0.7.0', '0.1.1', '1.4.1', '1.18.1', '1.0.3', '1.0.0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiona.__version__, gpd.__version__, mm.__version__, sp.__version__, np.__version__, pd.__version__, inequality.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summative = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = ['atlantic', 'preatl', 'premed', 'med']\n",
    "for part in parts:\n",
    "    path = folder + part + '.gpkg'\n",
    "    layers = [x[:-4] for x in fiona.listlayers(path) if 'blg' in x]\n",
    "    for l in layers:\n",
    "        buildings = gpd.read_file(path, layer=l + '_blg')\n",
    "        edges = gpd.read_file(path, layer=l + '_str')\n",
    "        tessellation = gpd.read_file(path, layer=l + '_tess')\n",
    "        blocks = gpd.read_file(path, layer=l + '_blocks')\n",
    "\n",
    "        buildings = buildings.merge(edges.drop(columns='geometry'), on='nID', how='left')\n",
    "        buildings = buildings.merge(tessellation.drop(columns=['bID', 'geometry', 'nID']), on='uID', how='left')\n",
    "        data = buildings.merge(blocks.drop(columns='geometry'), on='bID', how='left')\n",
    "\n",
    "        to_summ = ['sdbAre', 'sdbPer', 'ssbCCo', 'ssbCor', 'ssbSqu', 'ssbERI',\n",
    "                   'ssbElo', 'ssbCCD', 'stbCeA', 'mtbSWR', 'mtbAli', 'mtbNDi', 'ldbPWL',\n",
    "                   'stbSAl', 'ltcBuA', 'sssLin', 'sdsSPW', 'stsOpe', 'svsSDe', 'sdsAre', 'sdsBAr', 'sisBpM',\n",
    "                   'sdcLAL', 'sdcAre', 'sscERI', 'sicCAR', 'stcSAl', 'ldkAre', 'lskElo', 'likGra', 'meshedness',\n",
    "                   ]\n",
    "        spec = ['sdsLen']\n",
    "\n",
    "        if 'part' in data.columns:\n",
    "            for part in set(data.part):\n",
    "                subset = data.loc[data.part == part]\n",
    "                for col in to_summ:\n",
    "                    values = subset[col]\n",
    "                    values_IQ = mm.limit_range(values, rng=(25, 75))\n",
    "                    values_ID = mm.limit_range(values, rng=(10, 90))\n",
    "\n",
    "                    summative.loc[l + str(part), col + '_meanIQ'] = np.mean(values_IQ)\n",
    "                    summative.loc[l + str(part), col + '_rangeIQ'] = sp.stats.iqr(values)\n",
    "                    summative.loc[l + str(part), col + '_TheilID'] = Theil(values_ID).T\n",
    "                for col in spec:\n",
    "                    values = subset.loc[subset.case == 1][col]\n",
    "                    values_IQ = mm.limit_range(values, rng=(25, 75))\n",
    "                    values_ID = mm.limit_range(values, rng=(10, 90))\n",
    "\n",
    "                    summative.loc[l + str(part), col + '_meanIQ'] = np.mean(values_IQ)\n",
    "                    summative.loc[l + str(part), col + '_rangeIQ'] = sp.stats.iqr(values)\n",
    "                    summative.loc[l + str(part), col + '_TheilID'] = Theil(values_ID).T\n",
    "\n",
    "        else:\n",
    "            for col in to_summ:\n",
    "                values = data[col]\n",
    "                values_IQ = mm.limit_range(values, rng=(25, 75))\n",
    "                values_ID = mm.limit_range(values, rng=(10, 90))\n",
    "\n",
    "                summative.loc[l, col + '_meanIQ'] = np.mean(values_IQ)\n",
    "                summative.loc[l, col + '_rangeIQ'] = sp.stats.iqr(values)\n",
    "                summative.loc[l, col + '_TheilID'] = Theil(values_ID).T\n",
    "\n",
    "            for col in spec:\n",
    "                values = data.loc[data.case == 1][col]\n",
    "                values_IQ = mm.limit_range(values, rng=(25, 75))\n",
    "                values_ID = mm.limit_range(values, rng=(10, 90))\n",
    "\n",
    "                summative.loc[l, col + '_meanIQ'] = np.mean(values_IQ)\n",
    "                summative.loc[l, col + '_rangeIQ'] = sp.stats.iqr(values)\n",
    "                summative.loc[l, col + '_TheilID'] = Theil(values_ID).T\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summative.to_csv('data/summative_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seashore_streets",
   "language": "python",
   "name": "seashore_streets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}